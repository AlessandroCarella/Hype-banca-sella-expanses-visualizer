{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"ec_22_09_2023_31_08_2024.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf-8-sig: NO\n",
      "utf-16: NO\n",
      "cp1252: NO\n",
      "iso-8859-1: NO\n",
      "shift_jis: NO\n",
      "gb2312: NO\n",
      "gb18030: NO\n",
      "big5: NO\n",
      "iso-8859-2: NO\n",
      "utf-8: NO\n",
      "utf-16: NO\n",
      "utf-16-le: NO\n",
      "utf-16-be: NO\n",
      "utf-32: NO\n",
      "utf-32-le: NO\n",
      "utf-32-be: NO\n",
      "iso-8859-1: NO\n",
      "iso-8859-2: NO\n",
      "latin1: NO\n",
      "cp1252: NO\n",
      "cp1250: NO\n",
      "ascii: NO\n",
      "mac_roman: NO\n",
      "windows-1254: NO\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of encodings to test\n",
    "encodings = [\n",
    "    'utf-8-sig',  # utf-8 with BOM\n",
    "    'utf-16',     # utf-16 with BOM\n",
    "    'cp1252',     # Windows-1252 (Western European)\n",
    "    'iso-8859-1', # Latin-1 (Western European)\n",
    "    'shift_jis',  # Shift JIS (Japanese)\n",
    "    'gb2312',     # Simplified Chinese\n",
    "    'gb18030',    # Extended Simplified Chinese\n",
    "    'big5',       # Traditional Chinese (Taiwan, Hong Kong)\n",
    "    'iso-8859-2',  # Central and Eastern European\n",
    "    # others\n",
    "    'utf-8', 'utf-16', 'utf-16-le', 'utf-16-be', 'utf-32', 'utf-32-le', 'utf-32-be',\n",
    "    'iso-8859-1', 'iso-8859-2', 'latin1', 'cp1252', 'cp1250', 'ascii', 'mac_roman', 'windows-1254'\n",
    "]\n",
    "\n",
    "\n",
    "# Path to the problematic CSV file\n",
    "input_file = \"ec_22_09_2023_31_08_2024.csv\"\n",
    "\n",
    "# Loop through each encoding and try to read the file\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        # Try reading the file with the current encoding\n",
    "        df = pd.read_csv(input_file, encoding=encoding, error_bad_lines=False)\n",
    "        print(f\"{encoding}: OK\")  # Print 'OK' if successful\n",
    "    except Exception as e:\n",
    "        print(f\"{encoding}: NO\")  # Print 'NO' if an error occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: None\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "# Detect the encoding of the file\n",
    "with open('ec_22_09_2023_31_08_2024.csv', 'rb') as file:\n",
    "    result = chardet.detect(file.read())\n",
    "    print(f\"Detected encoding: {result['encoding']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been cleaned and saved as cleaned_file.csv\n"
     ]
    }
   ],
   "source": [
    "# Helper function to clean non-printable characters\n",
    "def clean_line(line):\n",
    "    return ''.join(c for c in line if c.isprintable())\n",
    "\n",
    "# Attempt to read and clean the file\n",
    "input_file = 'ec_22_09_2023_31_08_2024.csv'\n",
    "output_file = 'cleaned_file.csv'\n",
    "\n",
    "with open(input_file, 'rb') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "    for line in infile:\n",
    "        try:\n",
    "            # Try decoding with 'utf-8', if it fails, try 'latin1' which is more forgiving\n",
    "            decoded_line = line.decode('utf-8', errors='ignore')\n",
    "            cleaned_line = clean_line(decoded_line)\n",
    "            outfile.write(cleaned_line + '\\n')\n",
    "        except UnicodeDecodeError:\n",
    "            # If decoding fails, fall back to 'latin1'\n",
    "            decoded_line = line.decode('latin1', errors='ignore')\n",
    "            cleaned_line = clean_line(decoded_line)\n",
    "            outfile.write(cleaned_line + '\\n')\n",
    "\n",
    "print(f\"File has been cleaned and saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bad result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file appears to be binary, not a valid text CSV.\n"
     ]
    }
   ],
   "source": [
    "def is_binary(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        try:\n",
    "            # Read the first 1024 bytes\n",
    "            chunk = file.read(1024)\n",
    "            # If chunk contains null bytes, it's likely binary\n",
    "            if b'\\x00' in chunk:\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file: {e}\")\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "input_file = 'ec_22_09_2023_31_08_2024.csv'\n",
    "\n",
    "if is_binary(input_file):\n",
    "    print(\"The file appears to be binary, not a valid text CSV.\")\n",
    "else:\n",
    "    print(\"The file does not appear to be binary; check the encoding again.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i figured out the issue:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you try to change the extension of the file to xlsx the file opens straight away, that means that the file is actually an excel file which the extension of has been changed, just need to convert from xlsx to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('ec_22_09_2023_31_08_2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "every row of the file is now incapsulated in double quotes, so to fix that the code that follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ec_22_09_2023_31_08_2024.csv', index=False, quoting=csv.QUOTE_NONE, escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('ec_22_09_2023_31_08_2024.csv', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "with open ('ec_22_09_2023_31_08_2024.csv', 'w') as file:\n",
    "    for line in lines:\n",
    "        file.write(line.replace('\\,', ','))#remove extra chars from the file since we saved it with an escapechar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
